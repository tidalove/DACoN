{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "322708e7-7463-4e5d-be4e-d1976481176a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import time\n",
    "import json\n",
    "import torch\n",
    "import argparse\n",
    "from pathlib import Path\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ecdbd04c-47f6-4cd1-ac13-20bf7dd4d0b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from models import DACoNModel, DACoNTinyModel\n",
    "from data import KritaDACoNSingleDataset, krita_dacon_single_pad_collate_fn\n",
    "from utils import (\n",
    "    move_data_to_device,\n",
    "    load_config,\n",
    "    format_time,\n",
    "    colorize_target_image,\n",
    "    get_folder_names,\n",
    "    get_file_names,\n",
    "    extract_segment,\n",
    "    extract_color,\n",
    "    make_krita_inference_data_list,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "854de6e6-e3b2-4112-b77f-7ba2a93b32e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def check_seg_and_color(data_root, line_name, color_name):\n",
    "\n",
    "    # all frames have corresponding lines - get their basenames from lines\n",
    "    frame_names = get_file_names(os.path.join(data_root, line_name, \"target\"))\n",
    "    ref_frame_names = get_file_names(os.path.join(data_root, line_name, \"ref\"))\n",
    "\n",
    "    for frame_name in frame_names:\n",
    "        line_image_path = os.path.join(data_root, line_name, \"target\", frame_name)\n",
    "        seg_path = os.path.join(data_root, line_name, \"seg\", frame_name)\n",
    "        os.makedirs(os.path.join(data_root, line_name, \"seg\"), exist_ok=True)\n",
    "\n",
    "        if not(os.path.isfile(seg_path)):\n",
    "            extract_segment(line_image_path, seg_path)\n",
    "\n",
    "    for frame_name in ref_frame_names:\n",
    "        color_image_path = os.path.join(data_root, color_name, \"ref\", frame_name)\n",
    "        line_image_path = os.path.join(data_root, line_name, \"ref\", frame_name)\n",
    "        seg_path = os.path.join(data_root, line_name, \"seg\", \"ref\", frame_name)\n",
    "        color_json_path = os.path.join(data_root, line_name, \"seg\", f\"{frame_name.split('.')[0]}.json\")\n",
    "        os.makedirs(os.path.join(data_root, line_name, \"seg\", \"ref\"), exist_ok=True)\n",
    "\n",
    "        if not(os.path.isfile(seg_path)):\n",
    "            extract_segment(line_image_path, seg_path)\n",
    "        if not(os.path.isfile(color_json_path)):\n",
    "            extract_color(color_image_path, seg_path, color_json_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cb949e1d-7451-4d29-85e6-f1ea39899158",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run_inference(line_name, color_name,\n",
    "                  config='../configs/krita-inference.yaml',\n",
    "                  model_path='../checkpoints/dacon_krita.pth',\n",
    "                  data_root='./tmp'):\n",
    "\n",
    "    config = load_config(config)\n",
    "\n",
    "    version = config['version']\n",
    "    num_workers_val = config['datasets']['val']['num_worker']\n",
    "\n",
    "    batch_size = 1\n",
    "    save_images = config['val']['save_images']\n",
    "    save_json = config['val']['save_json']\n",
    "    save_path = data_root\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and config['num_gpu'] > 0 else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model = DACoNTinyModel(config['network'], version).to(device)\n",
    "\n",
    "    print(f\"Loading checkpoint {os.path.basename(model_path)}\")\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    \n",
    "    # --- Dataset and DataLoader setup ---\n",
    "    print(f\"Extracting Segment and Color\")\n",
    "    check_seg_and_color(data_root, line_name, color_name)\n",
    "\n",
    "    print(\"\\n--- Start Inference ---\")\n",
    "    inference_start_time = time.time()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        ref_data_list = make_krita_inference_data_list(data_root, line_name, color_name, is_ref = True)\n",
    "        ref_dataset = KritaDACoNSingleDataset(ref_data_list, data_root, is_ref=True, mode = \"infer\")\n",
    "        ref_dataloader = DataLoader(ref_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers_val, collate_fn=krita_dacon_single_pad_collate_fn)\n",
    "\n",
    "        all_seg_feats_ref = torch.empty(0, device=device)\n",
    "        all_seg_colors_ref = torch.empty(0, device=device)\n",
    "\n",
    "        for i, ref_data in enumerate(ref_dataloader):\n",
    "            ref_data = move_data_to_device(ref_data, device)\n",
    "            seg_colors_ref = ref_data['seg_colors']\n",
    "            seg_feats_ref, _ = model._process_single(ref_data['line_image'], ref_data['seg_image'], ref_data[\"seg_num\"])\n",
    "\n",
    "            for b in range(batch_size):\n",
    "                all_seg_feats_ref = torch.cat((all_seg_feats_ref, seg_feats_ref[b]), dim = 0)\n",
    "                all_seg_colors_ref = torch.cat((all_seg_colors_ref, seg_colors_ref[b]), dim = 0)\n",
    "\n",
    "            del ref_data, seg_feats_ref\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        inference_data_list = make_krita_inference_data_list(data_root, line_name, color_name, is_ref = False)\n",
    "        inference_dataset = KritaDACoNSingleDataset(inference_data_list, data_root, is_ref=False, mode = \"infer\")\n",
    "        inference_dataloader = DataLoader(inference_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers_val, collate_fn=krita_dacon_single_pad_collate_fn)\n",
    "\n",
    "        print(f\"\\n  Inference on {len(inference_dataset)} samples from ref on {color_name}\")\n",
    "\n",
    "        all_seg_feats_ref = all_seg_feats_ref.unsqueeze(0)\n",
    "        all_seg_feats_ref = all_seg_feats_ref.repeat(batch_size, 1, 1)\n",
    "\n",
    "        for i, data in enumerate(inference_dataloader):\n",
    "            data = move_data_to_device(data, device)\n",
    "            seg_feats_tgt, _ = model._process_single(data['line_image'], data['seg_image'], data[\"seg_num\"])\n",
    "            seg_sim_map = model.get_seg_cos_sim(all_seg_feats_ref.unsqueeze(1), seg_feats_tgt.unsqueeze(1))\n",
    "            seg_sim_map = seg_sim_map.squeeze(1)\n",
    "\n",
    "            frame_name = data[\"frame_name\"]\n",
    "            line_image_tgt = data[\"line_image\"] \n",
    "            seg_image_tgt = data[\"seg_image\"]\n",
    "            color_name = data[\"color_name\"]\n",
    "            line_name = data[\"line_name\"]\n",
    "\n",
    "            for b in range(batch_size):\n",
    "\n",
    "                seg_sim_map_batch = seg_sim_map[b]\n",
    "                nearest_patch_indices = torch.argmax(seg_sim_map_batch, dim=-1)\n",
    "\n",
    "                color_list_pred = all_seg_colors_ref[nearest_patch_indices]\n",
    "                color_list_pred = color_list_pred * 255\n",
    "\n",
    "                if save_images:\n",
    "                    image_pred = colorize_target_image(color_list_pred, line_image_tgt[b], seg_image_tgt[b], colors_only=True)\n",
    "                    folder_path = os.path.join(save_path, color_name[b], \"pred\")\n",
    "                    os.makedirs(folder_path, exist_ok=True)\n",
    "                    file_path  = os.path.join(folder_path, f\"{frame_name[b]}.png\")\n",
    "                    image_pred = image_pred.permute(2, 0, 1)\n",
    "                    save_image(image_pred, file_path)\n",
    "\n",
    "                if save_json:\n",
    "                    folder_path = os.path.join(save_path, color_name[b], \"pred\")\n",
    "                    os.makedirs(folder_path, exist_ok=True)\n",
    "                    json_file_path  = os.path.join(folder_path, f\"{frame_name[b]}.json\")\n",
    "                    color_dict = {str(idx + 1): [int(value) for value in color.tolist()] for idx, color in enumerate(color_list_pred)}\n",
    "\n",
    "                    with open(json_file_path, \"w\") as json_file:\n",
    "                        json.dump(color_dict, json_file)\n",
    "\n",
    "            print(f\"  Sample {i+1}/{len(inference_dataset)}\", end='\\r')\n",
    "\n",
    "        del data, seg_feats_tgt, seg_sim_map\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    del all_seg_feats_ref\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"\\n--- Inference complete! ---\")\n",
    "    inference_finish_time = time.time()\n",
    "    print(f\"\\nTotal time: {format_time(inference_finish_time - inference_start_time)}\")\n",
    "\n",
    "    # Log absolute peak memory usage\n",
    "    if torch.cuda.is_available():\n",
    "        peak_memory_gb = torch.cuda.max_memory_allocated() / 1024**3\n",
    "        print(f\"Peak GPU Memory Usage: {peak_memory_gb:.2f}GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "65fd7e30-3018-4173-af1f-31df18021fae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading checkpoint dacon_krita.pth\n",
      "Extracting Segment and Color\n",
      "\n",
      "--- Start Inference ---\n",
      "\n",
      "  Inference on 1 samples from ref on colors\n",
      "  Sample 1/1\n",
      "--- Inference complete! ---\n",
      "\n",
      "Total time: 00:00:05\n",
      "Peak GPU Memory Usage: 3.82GB\n"
     ]
    }
   ],
   "source": [
    "run_inference('lines','colors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "6e770a07-5e95-4750-97f2-2755eaefb460",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n",
    "def run_big_inference(line_name, color_name,\n",
    "                  config='../configs/inference.yaml',\n",
    "                  model_path='../checkpoints/dacon_v1_0.pth',\n",
    "                  data_root='./tmp'):\n",
    "\n",
    "    config = load_config(config)\n",
    "\n",
    "    version = config['version']\n",
    "    num_workers_val = config['datasets']['val']['num_worker']\n",
    "\n",
    "    batch_size = 1\n",
    "    save_images = config['val']['save_images']\n",
    "    save_json = config['val']['save_json']\n",
    "    save_path = data_root\n",
    "\n",
    "\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() and config['num_gpu'] > 0 else \"cpu\")\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    model = DACoNModel(config['network'], version).to(device)\n",
    "\n",
    "    print(f\"Loading checkpoint {os.path.basename(model_path)}\")\n",
    "    state_dict = torch.load(model_path, map_location=device)\n",
    "    model.load_state_dict(state_dict, strict=False)\n",
    "\n",
    "    \n",
    "    # --- Dataset and DataLoader setup ---\n",
    "    print(f\"Extracting Segment and Color\")\n",
    "    check_seg_and_color(data_root, line_name, color_name)\n",
    "\n",
    "    print(\"\\n--- Start Inference ---\")\n",
    "    inference_start_time = time.time()\n",
    "\n",
    "    model.eval()\n",
    "    with torch.no_grad():\n",
    "\n",
    "        ref_data_list = make_krita_inference_data_list(data_root, line_name, color_name, is_ref = True)\n",
    "        ref_dataset = KritaDACoNSingleDataset(ref_data_list, data_root, is_ref=True, mode = \"infer\")\n",
    "        ref_dataloader = DataLoader(ref_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers_val, collate_fn=krita_dacon_single_pad_collate_fn)\n",
    "\n",
    "        all_seg_feats_ref = torch.empty(0, device=device)\n",
    "        all_seg_colors_ref = torch.empty(0, device=device)\n",
    "\n",
    "        for i, ref_data in enumerate(ref_dataloader):\n",
    "            ref_data = move_data_to_device(ref_data, device)\n",
    "            seg_colors_ref = ref_data['seg_colors']\n",
    "            seg_feats_ref, _ = model._process_single(ref_data['line_image'], ref_data['seg_image'], ref_data[\"seg_num\"])\n",
    "\n",
    "            for b in range(batch_size):\n",
    "                all_seg_feats_ref = torch.cat((all_seg_feats_ref, seg_feats_ref[b]), dim = 0)\n",
    "                all_seg_colors_ref = torch.cat((all_seg_colors_ref, seg_colors_ref[b]), dim = 0)\n",
    "\n",
    "            del ref_data, seg_feats_ref\n",
    "            torch.cuda.empty_cache()\n",
    "\n",
    "        inference_data_list = make_krita_inference_data_list(data_root, line_name, color_name, is_ref = False)\n",
    "        inference_dataset = KritaDACoNSingleDataset(inference_data_list, data_root, is_ref=False, mode = \"infer\")\n",
    "        inference_dataloader = DataLoader(inference_dataset, batch_size=batch_size, shuffle=False, num_workers=num_workers_val, collate_fn=krita_dacon_single_pad_collate_fn)\n",
    "\n",
    "        print(f\"\\n  Inference on {len(inference_dataset)} samples from ref on {color_name}\")\n",
    "\n",
    "        all_seg_feats_ref = all_seg_feats_ref.unsqueeze(0)\n",
    "        all_seg_feats_ref = all_seg_feats_ref.repeat(batch_size, 1, 1)\n",
    "\n",
    "        for i, data in enumerate(inference_dataloader):\n",
    "            data = move_data_to_device(data, device)\n",
    "            seg_feats_tgt, _ = model._process_single(data['line_image'], data['seg_image'], data[\"seg_num\"])\n",
    "            seg_sim_map = model.get_seg_cos_sim(all_seg_feats_ref.unsqueeze(1), seg_feats_tgt.unsqueeze(1))\n",
    "            seg_sim_map = seg_sim_map.squeeze(1)\n",
    "\n",
    "            frame_name = data[\"frame_name\"]\n",
    "            line_image_tgt = data[\"line_image\"] \n",
    "            seg_image_tgt = data[\"seg_image\"]\n",
    "            color_name = data[\"color_name\"]\n",
    "            line_name = data[\"line_name\"]\n",
    "\n",
    "            for b in range(batch_size):\n",
    "\n",
    "                seg_sim_map_batch = seg_sim_map[b]\n",
    "                nearest_patch_indices = torch.argmax(seg_sim_map_batch, dim=-1)\n",
    "\n",
    "                color_list_pred = all_seg_colors_ref[nearest_patch_indices]\n",
    "                color_list_pred = color_list_pred * 255\n",
    "\n",
    "                if save_images:\n",
    "                    image_pred = colorize_target_image(color_list_pred, line_image_tgt[b], seg_image_tgt[b], colors_only=True)\n",
    "                    folder_path = os.path.join(save_path, color_name[b], \"pred\")\n",
    "                    os.makedirs(folder_path, exist_ok=True)\n",
    "                    file_path  = os.path.join(folder_path, f\"{frame_name[b]}.png\")\n",
    "                    image_pred = image_pred.permute(2, 0, 1)\n",
    "                    save_image(image_pred, file_path)\n",
    "\n",
    "                if save_json:\n",
    "                    folder_path = os.path.join(save_path, color_name[b], \"pred\")\n",
    "                    os.makedirs(folder_path, exist_ok=True)\n",
    "                    json_file_path  = os.path.join(folder_path, f\"{frame_name[b]}.json\")\n",
    "                    color_dict = {str(idx + 1): [int(value) for value in color.tolist()] for idx, color in enumerate(color_list_pred)}\n",
    "\n",
    "                    with open(json_file_path, \"w\") as json_file:\n",
    "                        json.dump(color_dict, json_file)\n",
    "\n",
    "            print(f\"  Sample {i+1}/{len(inference_dataset)}\", end='\\r')\n",
    "\n",
    "        del data, seg_feats_tgt, seg_sim_map\n",
    "        torch.cuda.empty_cache()\n",
    "\n",
    "    del all_seg_feats_ref\n",
    "    torch.cuda.empty_cache()\n",
    "\n",
    "    print(\"\\n--- Inference complete! ---\")\n",
    "    inference_finish_time = time.time()\n",
    "    print(f\"\\nTotal time: {format_time(inference_finish_time - inference_start_time)}\")\n",
    "\n",
    "    # Log absolute peak memory usage\n",
    "    if torch.cuda.is_available():\n",
    "        peak_memory_gb = torch.cuda.max_memory_allocated() / 1024**3\n",
    "        print(f\"Peak GPU Memory Usage: {peak_memory_gb:.2f}GB\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "910d57d8-3ec3-446d-8cb1-40545a9a26e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using device: cuda\n",
      "Loading DINOv2 model 'dinov2_vitl14' from PyTorch Hub...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using cache found in /home/kav/.cache/torch/hub/facebookresearch_dinov2_main\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DINOv2 model 'dinov2_vitl14' loaded successfully.\n",
      "Loading checkpoint dacon_v1_0.pth\n",
      "Extracting Segment and Color\n",
      "\n",
      "--- Start Inference ---\n",
      "\n",
      "  Inference on 1 samples from ref on colors\n",
      "  Sample 1/1\n",
      "--- Inference complete! ---\n",
      "\n",
      "Total time: 00:00:05\n",
      "Peak GPU Memory Usage: 7.17GB\n"
     ]
    }
   ],
   "source": [
    "run_big_inference('lines','colors')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a76b22a-b9e1-4b6a-b669-c2a427602d03",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (dacon)",
   "language": "python",
   "name": "dacon"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
